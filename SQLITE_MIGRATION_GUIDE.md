# SQLite Analytics Migration Guide

## üéØ Overview

The analytics system now supports two storage backends:
- **SQLite** (recommended): High-performance database with indexing
- **JSON** (legacy): Original format for backward compatibility

## üìä Performance Comparison

| Metric | JSON | SQLite | Improvement |
|--------|------|--------|-------------|
| Complex queries | 500ms+ | 10-50ms | 10-50x faster |
| Data export | 2-5s | 0.2-0.5s | 10x faster |
| Write performance | File I/O | WAL mode | 5x faster |
| Query flexibility | Limited | SQL power | Advanced |
| Scalability | ~10k sessions | 1M+ sessions | 100x better |

## üöÄ Migration Steps

### Step 1: Backup Current Data

```bash
cd /path/to/HazeBot
cp Data/app_analytics.json Data/app_analytics.json.backup
cp Data/error_analytics.json Data/error_analytics.json.backup
```

### Step 2: Run Migration Script (Dry Run)

Test the migration without writing to database:

```bash
python analytics/json_to_sqlite.py --dry-run
```

Expected output:
```
üìä Analytics Migration: JSON ‚Üí SQLite
============================================================
Data directory: Data
Database path: Data/analytics.db
Dry run: True

‚ö†Ô∏è DRY RUN MODE - No data will be written to database

üìä Migrating main analytics data...
‚úÖ Sessions: 1234
‚úÖ User stats: 56
‚úÖ Daily stats: 89

üêõ Migrating error analytics...
‚úÖ Error logs: 123

üì¶ Migrating archived data...
‚úÖ Files: 3
‚úÖ Archived sessions: 456
```

### Step 3: Run Actual Migration

```bash
python analytics/json_to_sqlite.py
```

This will:
1. Create `Data/analytics.db`
2. Migrate all sessions, user stats, daily stats
3. Migrate error logs
4. Migrate archived monthly files
5. Optimize database with VACUUM

### Step 4: Enable SQLite Backend

Edit `.env` file or set environment variable:

```bash
# .env file
ANALYTICS_BACKEND=sqlite
```

Or keep using JSON:

```bash
# .env file
ANALYTICS_BACKEND=json
```

### Step 5: Restart Bot

```bash
# Stop current bot
# Then restart with:
python start_with_api.py
```

Check logs for:
```
üìä Using SQLite backend: Data/analytics.db
Analytics aggregator initialized (backend=SQLite, ...)
```

## üîÑ Backward Compatibility

The system maintains full backward compatibility:

1. **JSON Mode**: Original behavior, no changes needed
2. **SQLite Mode**: New high-performance backend
3. **Seamless Switch**: Change `ANALYTICS_BACKEND` anytime
4. **Dashboard**: Works with both backends automatically

## üìÅ File Structure

After migration:

```
Data/
‚îú‚îÄ‚îÄ analytics.db              # SQLite database (new)
‚îú‚îÄ‚îÄ analytics.db-shm          # SQLite shared memory
‚îú‚îÄ‚îÄ analytics.db-wal          # SQLite write-ahead log
‚îú‚îÄ‚îÄ app_analytics.json        # Original data (keep as backup)
‚îú‚îÄ‚îÄ error_analytics.json      # Original errors (keep as backup)
‚îî‚îÄ‚îÄ analytics_archive/        # Archived monthly JSON files
    ‚îú‚îÄ‚îÄ 2025-09.json
    ‚îú‚îÄ‚îÄ 2025-10.json
    ‚îî‚îÄ‚îÄ 2025-11.json
```

## üóÉÔ∏è Database Schema

### Sessions Table
```sql
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    discord_id TEXT NOT NULL,
    username TEXT NOT NULL,
    started_at TEXT NOT NULL,
    ended_at TEXT,
    duration_minutes REAL,
    platform TEXT,
    device_info TEXT,
    app_version TEXT,
    ip_address TEXT,
    actions_count INTEGER,
    endpoints_used TEXT,      -- JSON
    screens_visited TEXT,     -- JSON
    created_at TEXT
);
```

### Indexes
- `idx_sessions_discord_id`
- `idx_sessions_started_at`
- `idx_sessions_platform`
- 10+ more optimized indexes

## üîç Querying SQLite Database

### Using SQLite CLI

```bash
sqlite3 Data/analytics.db

# View tables
.tables

# View schema
.schema sessions

# Example queries
SELECT COUNT(*) FROM sessions;
SELECT discord_id, COUNT(*) as session_count FROM sessions GROUP BY discord_id;
SELECT * FROM sessions WHERE started_at >= '2025-12-01' LIMIT 10;
```

### Using Python

```python
from api.analytics_db import AnalyticsDatabase

db = AnalyticsDatabase(Path("Data/analytics.db"))

# Get sessions
sessions = db.get_sessions(start_date="2025-12-01", limit=100)

# Get user stats
user_stats = db.get_user_stats()

# Complex queries
with db._get_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("""
        SELECT platform, COUNT(*) as count
        FROM sessions
        GROUP BY platform
        ORDER BY count DESC
    """)
    results = cursor.fetchall()
```

## üß™ Testing

### 1. Verify Migration

```bash
# Check database size
ls -lh Data/analytics.db

# Count records
sqlite3 Data/analytics.db "SELECT COUNT(*) FROM sessions;"
sqlite3 Data/analytics.db "SELECT COUNT(*) FROM user_stats;"
sqlite3 Data/analytics.db "SELECT COUNT(*) FROM daily_stats;"
```

### 2. Test Dashboard

1. Start bot with SQLite backend
2. Open dashboard: `http://localhost:8089/analytics/analytics_dashboard.html`
3. Verify all charts load correctly
4. Test date range filters
5. Check feature analytics section

### 3. Performance Test

```bash
# Run performance tests
python analytics/test_performance.py
```

## üêõ Troubleshooting

### Dashboard shows no data

**Cause**: SQLite database empty or backend mismatch

**Solution**:
```bash
# 1. Check backend setting
grep ANALYTICS_BACKEND .env

# 2. Verify database has data
sqlite3 Data/analytics.db "SELECT COUNT(*) FROM sessions;"

# 3. Re-run migration if needed
python analytics/json_to_sqlite.py
```

### Migration fails with "table already exists"

**Cause**: Database already exists from previous migration

**Solution**:
```bash
# Option 1: Delete and recreate
rm Data/analytics.db Data/analytics.db-*
python analytics/json_to_sqlite.py

# Option 2: Skip migration, use existing database
# (Data already migrated)
```

### "No module named 'api.analytics_db'"

**Cause**: Python path issue

**Solution**:
```bash
# Run from HazeBot root directory
cd /path/to/HazeBot
python analytics/json_to_sqlite.py
```

### Performance not improved

**Cause**: Database not optimized

**Solution**:
```bash
# Run VACUUM to optimize
sqlite3 Data/analytics.db "VACUUM; ANALYZE;"
```

## üîß Advanced Configuration

### Custom Database Path

```python
# In app.py
from pathlib import Path
from api.analytics_db import AnalyticsDatabase

db_path = Path("/custom/path/analytics.db")
db = AnalyticsDatabase(db_path)
```

### Batch Interval Tuning

```python
# In app.py
analytics = analytics_module.AnalyticsAggregator(
    analytics_file,
    batch_interval=300,  # 5 minutes (default)
    cache_ttl=300        # 5 minutes (default)
)
```

For high-traffic environments:
- Increase `batch_interval` to 600-900s (reduces writes)
- Increase `cache_ttl` to 600-900s (more cache hits)

### Database Maintenance

Run monthly to reclaim space:

```bash
# Optimize database
sqlite3 Data/analytics.db "VACUUM; ANALYZE;"

# Check database integrity
sqlite3 Data/analytics.db "PRAGMA integrity_check;"
```

## üìà Migration Checklist

- [ ] Backup current JSON files
- [ ] Run dry-run migration
- [ ] Review migration output
- [ ] Run actual migration
- [ ] Verify database size and record counts
- [ ] Set `ANALYTICS_BACKEND=sqlite` in .env
- [ ] Restart bot
- [ ] Test dashboard functionality
- [ ] Run performance tests
- [ ] Monitor logs for errors
- [ ] Keep JSON backups for 30 days

## üí° Tips

1. **Keep JSON backups**: Don't delete JSON files immediately after migration
2. **Test in TestData first**: Use `--data-dir TestData` for testing
3. **Monitor database size**: SQLite is efficient but grows over time
4. **Use VACUUM monthly**: Reclaims space and rebuilds indexes
5. **Archive old data**: Consider moving old sessions to separate database

## üÜò Rollback to JSON

If you need to rollback:

1. Set `ANALYTICS_BACKEND=json` in .env
2. Restart bot
3. System will use original JSON files
4. No data loss (JSON files never deleted)

## üìû Support

If you encounter issues:
1. Check logs in `Logs/` directory
2. Run migration with `--dry-run` to diagnose
3. Verify database integrity
4. Test with TestData first
5. Keep JSON backups as fallback

---

**Last Updated**: December 2, 2025  
**Version**: 1.0  
**Tested With**: Python 3.11+, SQLite 3.35+
